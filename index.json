[{"content":"最近在用 Go 刷算法题的过程中，切实体验到了三目运算缺失的痛苦。正好之前在探讨 Go 中 init 的处理时，了解了一些 Go 编译器的具体工作流程，因此有能力在其基础上进行修改了，于是便想着为 Go 添加三目运算。\n","permalink":"https://xinrea.cn/posts/ternary-in-go/","summary":"最近在用 Go 刷算法题的过程中，切实体验到了三目运算缺失的痛苦。正好之前在探讨 Go 中 init 的处理时，了解了一些 Go 编译器的具体工作流程，因此有能力在其基","title":"为 Go 添加三目运算符"},{"content":"CAP 定理 CAP 原则又称 CAP 定理，指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）。CAP 原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。\n显然分区容错性 P 是必须要满足的，因为在分布式系统中网络是不可靠的，这意味着系统很可能会被分割成多个区域（也等效于节点失效，因为客观上无法分辨是网络原因还是节点原因）。如果此时不能保证分区容错性，那么也就是所一旦发生分区（或者说节点失效），分布式系统就无法正常工作了；由于分布式系统中含有许多节点，这会导致系统的故障率远远大于单体，这显然是不能接受的，与使用分布式系统的初衷背道而驰。\n因此在满足 P 的前提下，也就是说当节点失效时，C 和 A 之间的取舍就成为了分布式系统设计中的核心问题。在实际的分布式系统中，我们看到的所有设计都是围绕这两点来进行的。\n从单体到多体 假设我们有一个服务 A 运行在单个节点上，它的功能是 resp = f(req)。这个服务十分重要，我们希望它能够 7x24 小时运行，不间断地提供服务。那么我们就需要考虑如何保证这个服务的可用性。\n如果服务 A 是无状态的，也就是说服务 A 的响应 resp 只取决于 req，而与之前的请求无关，那么我们可以通过复制的方式来保证服务的可用性。我们可以在任意多的节点上运行服务 A，然后将请求以任意形式分发到可用的节点上，从而保证服务的可用性。这类无状态服务处理起来比较简单，因此在微服务拆分时，我们尽量将服务拆分成无状态的服务，这样可以大大降低系统的复杂度。\n但是，在实际中比较重要的服务往往是有状态的，也就是说服务 A 的响应 resp 不仅取决于 req，还取决于之前的请求。\n1. 备份（Master-Slave/Leader-Follower/Primary-Replica） 针对有状态服务，最简单的方法就是备份，我们可以在另一个节点上运行一个服务 B，它的功能也是 resp = f(req)。当请求到达时，我们将请求同时发送到 A 和 B，然后将 A 或者 B 的响应返回给客户端。这样，B 节点的状态与 A 节点一致，当 A 节点发生故障时，我们可以切换到 B 节点，让其接替服务。我们称 A、B 这些节点组成了一个集群。\n想想这样一个场景，请求到达集群后，由于网络原因（或者故障，集群视角无法区分），其中一个节点没有响应这个请求，那么这意味着这个节点的状态与其他节点不一致，这时我们应该怎么办呢？\n1.1 拥抱一致性 保证强一致性（线性一致性）可以想到以下几种处理方法\n对外响应处理失败，那么对于集群内的 N 个节点，一旦有一个节点出现错误，其他所有节点都要撤销操作，保证与失败的节点状态一致 不断重试，最终对外响应处理成功。但是这样会导致请求的响应时间变长，很有可能请求永远也不会成功 对外响应处理成功，剔除故障节点，将故障节点定义到一致性范围之外。这样做的问题是，如果故障节点恢复了，那么它的状态就会与其他节点不一致，一致性要求集群内节点必须与集群内其他节点状态一致，这意味着故障节点永远无法恢复；如果要加入或者恢复节点，都要停止对外服务，等待集群内所有节点状态一致再对外开放。遗憾的是，节点故障在分布式系统中是常态，这样做显然是不可行的 可见为了保证一致性，我们必须要牺牲可用性，这与 CAP 原则是一致的。\n1.2 拥抱可用性 如果我们选择可用性，那么我们可以采取以下处理方法\n如果部分节点处理成功，那么就对外响应处理成功 这里的 部分 可以是一个，可以是大部分，可以是权重最高的几个，也可以是随机的几个，可以自由选择合适的策略。\n这样做的问题是，后续请求发送到状态不一致的节点上时，处理很可能是错误的；好处是可用性大大提升，至少请求都及时处理了。\n虽然能够完成请求，但是如果对请求的处理都是错的，那么可用性再高也没有意义；还好这里 错 的定义还有可商量的余地，使得我们可以在一致性和可用性之间做出权衡。\n1.3 拥抱最终一致性 其实在强一致性（线性一致性）到最终一致性之间，还有许多不同等级的一致性；在此直接考虑要求最低的最终一致性，是因为在实际中最多考虑的还是可用性，因此在一致性方面牺牲了许多。\n最终一致性是指，在没有新的请求时，集群内的节点最终会达到一致状态，显然这里的时间差越短越好。实际上，可以结合 1.1 和 1.2 的方法来实现这一点。\n回顾以下两种方法：\n[一致性] 对外响应处理成功，剔除故障节点，将故障节点定义到一致性范围之外 [可用性] 如果部分节点处理成功，那么就对外响应处理成功 一致性方面，我们定义符合最终一致性的节点集合为 E，其中的强一致性节点组成集合 C，那么有\n$$C \\subseteq E$$\n集群的状态为其中状态最新的节点状态。根据请求的类别，我们可以将请求分为两类：\n强一致性请求 CR：例如涉及到写操作的请求，这类请求只能发送到强一致性节点集合 C 上，原因是：写操作需要改变集群的状态，将集群看作状态机，初始状态 Sk 在收到操作 Wj 后，状态改变为 Sk+1；同理要让状态最终一致，那么要求 Wj 必须发送到状态为 Sk 的节点上，这样才能保证集群最终状态一致；即涉及到状态改变的操作，只能发送到 C 上 最终一致性请求 ER：首先这类请求不涉及集群状态变化，可以发送到最终一致性节点集合 E 上；其次要求可以容忍读取到旧数据 我们来看看强一致性节点集合 C 的性质：\n从 1.1 中得知，对于强一致性节点集合 C，C 中元素越多，集群处理强一致性请求的可用性越低\n其中红线假设单节点可用性 99%；蓝线假设单节点可用性 99.9%；绿线假设单节点可用性 99.99%；紫线为可用性 90% 线。\n可见扩展 C 将使得集群可用性急剧下跌，且十分依靠单节点可用性。另一方面，在实现时，需要将 CR 发送到 C 中的每一个节点，造成了大量的带宽浪费；其次，为了维护 C，需要实现一个中间件用于接收分发 CR，并在节点故障时将其移出 C，而且需要统计所有 C 中节点的响应结果，集群对于 CR 的吞吐性能为 C 中各节点性能的最小值，造成了吞吐性能的急剧下滑；最后，中间件如果出现问题会导致集群不可用，因此中间件还需要集群化。\n由于以上的众多原因，实际上在集群中 C 往往只包含一个节点 C0，用于集群处理 CR 请求，这样做有以下优缺点：\n优点：\nE 节点同步简单，集群状态等同于 C0 的状态；其他节点与 C0 同步即可 CR 请求处理简单，直接交给 C0 处理即可 缺点：\nC0 挂掉会导致集群无法对 CR 请求提供服务 分布式中没有十全十美的解决方案，都需要有所取舍，但最终有很多项目都选用了 C 只包含一个节点的形式。例如 MySQL、Redis、Kafka、Zookeeper、使用 Raft 机制的其他项目等等，都使用了这一设计思想。\n当然要使用这种设计，得解决一个核心问题，也就是弥补该设计的缺点：C0挂掉会导致集群无法对 CR 请求提供服务。显然我们不可能启用全新的节点来替代，而集群中有着许多接近 C0 的状态的最终一致性节点，因此可以从它们中选出新的 C0。当然，如果选出的节点状态与原来的 C0 不同，则会导致数据的丢失，好在有着一系列机制来保证这些节点的最终一致性，而且 C0 不可用时集群状态不会再更新，相当于提供了一个等待同步的机会，因此可以尽可能避免数据丢失情况的产生，这一点后续再详细阐述。\n因此现在我们遇到了一个新问题，当 C0 挂掉时，该如何切换节点来替代 C0。\n1.4 如何切换 1.4.1 人工干预 切换的方法有很多种，其中最简单的方法就是人工干预，当 A 节点发生故障时，我们手动将请求切换到 B 节点。这种方法的缺点是服务无法使用，直到人工干预完成。这种方法看起来很蠢，但是如果不是使用在故障处理上，还是有可取之处的。\n例如 MySQL 集群的迁移就可以用到这种方式；首先将新的节点加入最终一致性节点集合 E，也就是作为 Slave 节点来同步 Master 节点的数据。待到数据同步完成，ER 操作实际上已经可以切换到新节点上了；最后手动在新节点中启用一个 Master 节点，替换旧 Master 节点，然后将 CR 请求切换到新 Master 节点即可。\n显然最后切换 Master 节点时与 C0 节点故障的处理等效，因此集群无法提供服务。\n1.4.2 哨兵机制 为了自动化完成前面提到的人工干预方法，引入了哨兵机制。其本质上跟人工干预相同，不过是使用一个服务来替代人完成这一操作。优点是无需在原有服务上做修改，哨兵服务与原服务独立运行。\n显然，哨兵服务的可用性也需要用集群来保证，因此 Redis 哨兵模式架构如下所示：\ngraph TD subgraph Sentinel A1(Sentinel Leader) \u0026lt;--\u0026gt; A2(Sentinel 1) A3(Sentinel 2) \u0026lt;--\u0026gt; A2 A3(Sentinel 2) \u0026lt;--\u0026gt; A1 end subgraph Redis B(Master) \u0026lt;--\u0026gt; C(Slave 1) B \u0026lt;--\u0026gt; D(Slave 2) end Sentinel --\u0026gt; Redis 哨兵服务监控所有 Redis 节点的状态，以便当 Master 节点宕机后进行自动切换。这样就解决了 Redis Master 节点宕机后新 Matser 的切换问题。\n但是和 Redis 集群一样，哨兵服务在执行各种操作时，执行操作的主体只能是一个节点（Leader），其他节点作为备份（Follower），以达成一定的一致性和可用性。那么，当 Sentinel Leader 挂掉后，该如何切换新的 Leader 节点呢？如果还是使用哨兵机制的话，那么需要启用 Sentinel 的 Sentinel 服务，最终会无限套娃下去。\n为了解决这一问题，我们需要集群本身具有 C0 节点的切换机制，不能依赖外部服务。\n1.4.3 分布式共识算法 前面在描述哨兵集群中的节点时，使用的是 Leader/Follower 而不是 Master/Slave，这是因为哨兵集群使用 Raft 算法实现了 C0 的自动切换。通常我们将使用选举算法实现的 C0 称为 Leader，实际上集群视角来看都为主从模式，只是“主”的故障迁移使用了不同的机制来实现；避免使用 Master 和 Slave 等词汇也有政治正确的体现（例如 GitHub 将主分支默认名称 Master 更改为 Main)。\n首先要说明，此处不讨论拜占庭将军问题，因为我们认为对集群中节点具有完全的控制权，因此集群内部的节点均按照规定的机制运行，出现的所有错误情况均是可预测的。\n因此这里讨论的分布式共识没有 BTC 等区块链项目的共识机制严格，但仍需考虑各种异常情况的处理。\n提到分布式共识算法就得从 Paxos 算法 说起。Paxos 算法模拟了一个小岛上通过决议的流程，一个值的确定需要多数人发起提案（Prepare 阶段）后，得到多数人的同意（Accept 阶段）。其中每个人都要维护一个Proposal ID，已确保只处理自身视角里最新的 Proposal，Proposal ID 将会在 Prepare 和 Accept 阶段中更新。\n这样的 Basic Paxos 算法的问题在于，只要多数人就可发起提案，因此很可能前一个提案还未处理完便发起了新的提案，导致 Accept 阶段有些人得知了新的提案便不再处理旧提案，使得旧提案无法得到多数人的确认，此时若再次发起提案，那么刚刚的新提案也会遇到同样的问题，造成活锁；同时，这样的流程仅能确定一个值，无法满足实际需求。\n为了解决以上 Basic Paxos 算法的缺陷，很自然的提出了 Multi-Paxos 算法。\n","permalink":"https://xinrea.cn/posts/distribute-system-design/","summary":"CAP 定理 CAP 原则又称 CAP 定理，指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Part","title":"分布式系统设计思路总览"},{"content":" 本文中引用的源码均标注了 Golang 源码仓库链接，branch 为 release-branch.go1.21（本文在编写时 Go 1.21 还未正式发布，正式版可能会有少量变化）。\ninit() 在不规范使用情况下产生的现象 在同一个 go 文件里，初始相关操作的执行顺序是 const -\u0026gt; var -\u0026gt; init()。显然，如果同一个文件里有多个 init()，那么将按照声明顺序来执行。\n如果 Package 的 init() 分布在不同的文件里，将会按照什么顺序来执行呢？\n有如下场景：\n1main.go 2a/b.go 3a/c.go 1// main.go 2package main 3 4import \u0026#34;go-init/a\u0026#34; 5 6func main() { 7 a.A() 8} 1// a/b.go 2package a 3 4func init() { 5 println(\u0026#34;b init\u0026#34;) 6} 7 8func A() int { 9 println(\u0026#34;A\u0026#34;) 10 return 0 11} 1// a/c.go 2package a 3 4func init() { 5 println(\u0026#34;c init\u0026#34;) 6} 执行 go run main.go，得到输出：\n1b init 2c init 3A 接下来将 a/b.go 改名为 a/d.go，再次执行 go run main.go，输出：\n1c init 2b init 3A 可以看到有 [现象]：a/b.go 和 a/c.go 的 init() 函数的执行顺序是按照文件名的字母顺序来的，将 a/b.go 改名后，其文件名顺序排在了 a/c.go 之后，最终 init() 执行也排在了之后。\n还有更多复杂的情况，例如：\n如果 import 的包之间存在依赖关系，那么这些包的 init() 的执行顺序是怎样的？ 如果 Package 的 init() 分布在不同的文件里，而且这些文件里有交叉依赖的 var 全局变量，那么 init() 和这些全局变量初始化的执行顺序又是怎样的？ 实际上，要真正弄清楚这些，需要深入 Go 编译器，从根源弄清原理。init() 的处理是 Go 编译过程中的重要一环。\n编译的起点 gc.Main() Golang 编译器相关源码位于 go/src/cmd/compile/。\nGo 编译处理的单位是 Package，得到的结果是 Object 文件。在一次编译过程开始时会读取 Package 中所有文件内容进行词法和语法分析。我们很容易就能找到编译器的入口文件 main.go：\n1// https://github.com/golang/go/blob/d8117459c513e048eb72f11988d5416110dff359/src/cmd/compile/main.go#L45 2func main() { 3 // disable timestamps for reproducible output 4 log.SetFlags(0) 5 log.SetPrefix(\u0026#34;compile: \u0026#34;) 6 7 buildcfg.Check() 8 archInit, ok := archInits[buildcfg.GOARCH] 9 if !ok { 10 fmt.Fprintf(os.Stderr, \u0026#34;compile: unknown architecture %q\\n\u0026#34;, buildcfg.GOARCH) 11 os.Exit(2) 12 } 13 14 gc.Main(archInit) 15 base.Exit(0) 16} gc.Main() 完成了整个编译流程，其内容是本文的重点；编译流程本身比较清晰，但内容很多，在本文中主要关心 init() 相关的处理。\n为了方便理解，请先阅读编译器部分的 README.md，了解编译器的基本流程和相关概念；下面也简单介绍一下编译器的流程，补充一些细节，便于理解为什么 Go 编译器现在是这样一个结构。\n编译流程 1. Parsing 词法和语法分析得到 AST（Abstract Syntax Tree，抽象语法树），每个 AST 等价于一个源文件。关于树的结构和节点的定义见 internal/syntax/nodes.go，Go 源码中的所有元素都能在这里找到对应的结构，极其基础和重要。\n例如：\n1// X[Index[0] : Index[1] : Index[2]] 2SliceExpr struct { 3 X Expr 4 Index [3]Expr 5 // Full indicates whether this is a simple or full slice expression. 6 // In a valid AST, this is equivalent to Index[2] != nil. 7 // TODO(mdempsky): This is only needed to report the \u0026#34;3-index 8 // slice of string\u0026#34; error when Index[2] is missing. 9 Full bool 10 expr 11} 我们可以从中知道 slice[:] 操作实际上可以有三个参数，分别表示指针（新起始位置）、长度和容量。\n同时也可以看到 Comments 相关结构仍在开发之中，后续可能会加入 AST 用于生成更加结构化的文档。\n2. Type checking 类型检查，types2 是从 go/types 移植而来的，在这里需要结合发展历史来理解。\n在一开始，Go 的编译器是使用 C 来实现的。到 Go 1.5 版本，实现了自举，其中编译过程中类型检查使用的是 Go 实现的传统检查算法，位于 internal/gc/typecheck.go；同时 Go 1.5 版本在标准库里面加入了 go/types，便于开发者开发 Go 代码分析工具。随着各种代码检查工具的涌现，go/types 发展迅猛，相比较而言，internal/gc/typecheck.go 涉及编译器过于底层，发展较慢。\n直到 Go 1.17 开始开发，需要将泛型作为实验特性加入，此时编译器的类型检查已经无法满足要求，好在 go/types 已经十分成熟，借助其强大的类型推导能力，在编译器中实现了对泛型的处理；这也是 internal/types2 和 go/types 一开始相同的原因。后续对 go/types 问题的修复也应同步到 types2，这样才能保证编译器和代码分析工具的一致性，同时也相当于让更多人参与了编译器的改进；当然，编译器自身也有些特殊需求需要在 types2 中实现。由于现在有两种并行的实现，因此 internal/gc/typecheck.go 被抽取出来，成为了 internal/typecheck 包。\n在 Go 1.5 之前，编译器使用 C 实现，不存在 Go 实现的类型检查。\n在 Go 1.5 - 1.16，编译器使用 Go 实现，类型检查使用 gc/typecheck.go，官方提供了 go/types 包。\n在 Go 1.17 时泛型还只是可选项，因此编译器提供了参数 -G 来选择是否开启泛型，实际上，当 G=0 时编译器会使用旧的 typecheck 来进行类型检查；当 G=3 时使用 types2 （go/types移植而来）进行类型检查以支持泛型。\n在 Go 1.18 正式推出泛型以后，-G 参数仍然存在，只不过默认值改成了 G=3，也就是说，现在编译器默认使用 types2 进行类型检查。\n在 Go 1.19 推出后，-G 参数被移除，编译器只能使用 types2 进行类型检查。\n例如 Commit: 8fd2875：\n修改 src/go/types 后，也同步修改了 src/cmd/compile/internal/types2 下的内容。\n3. IR construction(\u0026ldquo;noding\u0026rdquo;) IR（Intermediate Representation，中间表示）是一种介于 AST 和汇编代码之间的表示，是一种更加抽象的表示，能够更好地表示语义。这一步就是将 AST 转换为 IR，这个过程称作 noding。\n在 Go 1.17 之前，并没有 IR 的概念，或者说有，但是还不叫 IR。\n在 Go 1.17，当 G=0 时，编译器可选择使用 internal/typecheck 进行类型检查，因此对应使用 noder 进行 noding；当 G=3 时，编译器使用 types2 进行类型检查，因此使用相应的新实现来进行 noding， 称之为 noder2。\n在 Go 1.18，同样可以通过 -G 参数来选择使用 internal/typecheck 或者 types2 进行类型检查，因此 noder 和 noder2 仍然是并存的。\n在 Go 1.19 之后，编译器只能使用 types2 进行类型检查，因此 noder2 也是唯一的 noding 实现。\n其实 IR 也是一种形式的 AST，被称为 GC AST（Go Compiler AST）。那么为什么要转换呢？主要原因是自 Go 1.5 实现自举时，参考旧 C 的实现来完成了 AST 上的类型检查等等后续操作；但是新的 Go 实现的词法语法分析得到的 AST 只是分别与源文件对应，还未处理 import 以及合并，并不完整；好在这个转换并不复杂。\n旧的处理流程如下所示：\n1// 旧处理流程 Go 1.5 - 1.16 2[AST1,AST2,...] := Parse([file1,file2,...]) 3 4// 处理 import，合并 AST 5IR := Noder([AST1,AST2,...]) 6 7// 类型检查 8Typecheck(IR) 9MiddleEndOP(IR) 10SSA := SSAGen(IR) 11MACHINE_CODE := CodeGen(SSA) 在 Go 1.17 引入 types2 后，由于 types2 是作用于 AST 上的，因此新的处理流程变成了：\n1// 新处理流程 Go 1.17 2[AST1,AST2,...] := Parse([file1,file2,...]) 3 4#if G=3 5 // 处理 import，类型检查，处理泛型 6 TypeInfo := Types2([AST1,AST2,...]) 7 IR := Noder2([AST1,AST2,...],TypeInfo) 8#elseif G=0 9 // 处理 import，合并 AST 10 IR := Noder([AST1,AST2,...]) 11#endif 12 13// 之后完全一致 14Typecheck(IR) 15MiddleEndOp(IR) 16SSA := SSAGen(IR) 17MACHINE_CODE := CodeGen(SSA) noder2 的实现位于 internal/ir。会发现当 G=3 时，虽然用了 internal/types2 来进行类型检查，但是后续在 IR 上还是跑了一遍 internal/typecheck，在这里有许多原因，主要是 internal/typecheck 会对 IR 进行一些修改调整，因此还需要保留，详情可以看这里的注释：internal/noder/unified.go#L51。\n在 Go 1.18 又引入了 Unified IR（GOEXPERIMENT=unified 开启），于是乎三种流程并行存在：\n1// 新处理流程 Go 1.18 2[AST1,AST2,...] := Parse([file1,file2,...]) 3 4#if Unified 5 IR := Unified([AST1,AST2,...]) 6#else 7 #if G=3 8 // 处理 import，类型检查，处理泛型 9 TypeInfo := Types2([AST1,AST2,...]) 10 IR := Noder2([AST1,AST2,...],TypeInfo) 11 #elseif G=0 12 // 处理 import，合并 AST 13 IR := Noder([AST1,AST2,...]) 14 #endif 15 Typecheck(IR) 16#endif 17 18MiddleEndOp(IR) 19SSA := SSAGen(IR) 20MACHINE_CODE := CodeGen(SSA) 在 Go 1.19 移除了 G=0 的流程：\n1// 新处理流程 Go 1.19 2[AST1,AST2,...] := Parse([file1,file2,...]) 3 4#if Unified 5 IR := Unified([AST1,AST2,...]) 6#else 7 // 处理 import，类型检查，处理泛型 8 TypeInfo := Types2([AST1,AST2,...]) 9 IR := Noder2([AST1,AST2,...],TypeInfo) 10 Typecheck(IR) 11#endif 12 13MiddleEndOp(IR) 14SSA := SSAGen(IR) 15MACHINE_CODE := CodeGen(SSA) 在 Go 1.21 正式启用了 Unified IR，因此 unified 也就是唯一的 noding 实现了，确实实现了统一，欢迎来到 Go 1.21 ！（实际上需要处理的东西其实没有改变，只是整合在了 Unified 内，因此原来的包还依然存在）\n1// 新处理流程 Go 1.21 2[AST1,AST2,...] := Parse([file1,file2,...]) 3 4IR := Unified([AST1,AST2,...]) 5 6MiddleEndOp(IR) 7SSA := SSAGen(IR) 8MACHINE_CODE := CodeGen(SSA) 下面是各种 noder 在不同版本的存在状态：\nGo 1.17 之前：noder Go 1.17: noder, noder2 Go 1.18: noder, noder2, unified Go 1.19: noder2, unified Go 1.20: noder2, unified Go 1.21: unified 4. Middle end internal/deadcode (dead code elimination) internal/inline (function call inlining) internal/devirtualize (devirtualization of known interface method calls) internal/escape (escape analysis) 5. Walk，SSA Gen 以及机器码生成 Walk 遍历 IR，拆分复杂的语句以及将语法糖转换成基础的语句 SSA Gen 将 IR 转化为 Static Single Assignment (SSA) 形式，此时还与具体的机器无关 机器码生成会根据架构以及更多机器相关的信息，对 SSA 进行优化；同时进行栈帧分配，寄存器分配，指针存活分析等等，最终经过汇编器 cmd/internal/obj 生成机器码。 流程中 init 相关的处理 前面我们了解了 Go 编译器的流程，以及其发展变化的历史。接下来我们来看看其中 init 相关的具体处理。\n1// https://github.com/golang/go/blob/d8117459c513e048eb72f11988d5416110dff359/src/cmd/compile/internal/gc/main.go#L59 2// Main parses flags and Go source files specified in the command-line 3// arguments, type-checks the parsed Go package, compiles functions to machine 4// code, and finally writes the compiled package definition to disk. 5func Main(archInit func(*ssagen.ArchInfo)) { 6 ... 7 // Parse and typecheck input. 8 noder.LoadPackage(flag.Args()) 9 ... 10 // Create \u0026#34;init\u0026#34; function for package-scope variable initialization 11 // statements, if any. 12 // 13 // Note: This needs to happen early, before any optimizations. The 14 // Go spec defines a precise order than initialization should be 15 // carried out in, and even mundane optimizations like dead code 16 // removal can skew the results (e.g., #43444). 17 pkginit.MakeInit() 18 ... 19 // Build init task, if needed. 20 if initTask := pkginit.Task(); initTask != nil { 21 typecheck.Export(initTask) 22 } 23 ... gc.Main() 流程中主要有以上三部分对 init 进行了处理，接下来我们分别看看这三部分。\nnoder.LoadPackage() 1// https://github.com/golang/go/blob/d8117459c513e048eb72f11988d5416110dff359/src/cmd/compile/internal/noder/noder.go#L27 2func LoadPackage(filenames []string) { 3 ... 4 noders := make([]*noder, len(filenames)) 5 ... 6 go func() { 7 for i, filename := range filenames { 8 ... 9 go func() { 10 ... 11 f, err := os.Open(filename) 12 ... 13 p.file, _ = syntax.Parse(fbase, f, p.error, p.pragma, syntax.CheckBranches) // errors are tracked via p.error 14 }() 15 } 16 }() 17 ... 18 unified(m, noders) 19} 可以看到 LoadPackage() 会并行的对每个文件进行读取以及词法语法分析，构建 AST。并将得到的 AST 列表传递给 unified() 进行统一处理。\n1// https://github.com/golang/go/blob/d8117459c513e048eb72f11988d5416110dff359/src/cmd/compile/internal/noder/unified.go#L71 2func unified(m posMap, noders []*noder) { 3 ... 4 data := writePkgStub(m, noders) 5 ... 6 target := typecheck.Target 7 r := localPkgReader.newReader(pkgbits.RelocMeta, pkgbits.PrivateRootIdx, pkgbits.SyncPrivate) 8 r.pkgInit(types.LocalPkg, target) 9 10 // 后面均为 `internal/typecheck` 的处理，与 init 无关 11 // Type-check any top-level assignments. We ignore non-assignments 12 // here because other declarations are typechecked as they\u0026#39;re 13 // constructed. 14 for i, ndecls := 0, len(target.Decls); i \u0026lt; ndecls; i++ { 15 switch n := target.Decls[i]; n.Op() { 16 case ir.OAS, ir.OAS2: 17 target.Decls[i] = typecheck.Stmt(n) 18 } 19 } 20 21 readBodies(target, false) 22 23 // Check that nothing snuck past typechecking. 24 for _, n := range target.Decls { 25 if n.Typecheck() == 0 { 26 base.FatalfAt(n.Pos(), \u0026#34;missed typecheck: %v\u0026#34;, n) 27 } 28 29 // For functions, check that at least their first statement (if 30 // any) was typechecked too. 31 if fn, ok := n.(*ir.Func); ok \u0026amp;\u0026amp; len(fn.Body) != 0 { 32 if stmt := fn.Body[0]; stmt.Typecheck() == 0 { 33 base.FatalfAt(stmt.Pos(), \u0026#34;missed typecheck: %v\u0026#34;, stmt) 34 } 35 } 36 } 37 ... 38} 其中 writePkgStub() 完成了类型检查。接下来的调用链有点长，在这里就不放源代码了，大致流程如下：\nwritePkgStub() -\u0026gt; noder.checkFiles -\u0026gt; conf.Check() -\u0026gt; Checker.Files() -\u0026gt; check.checkFiles()\n1// https://github.com/golang/go/blob/d8117459c513e048eb72f11988d5416110dff359/src/cmd/compile/internal/types2/check.go#L335 2func (check *Checker) checkFiles(files []*syntax.File) (err error) { 3 ... 4 print(\u0026#34;== initFiles ==\u0026#34;) 5 check.initFiles(files) 6 7 print(\u0026#34;== collectObjects ==\u0026#34;) 8 check.collectObjects() 9 10 print(\u0026#34;== packageObjects ==\u0026#34;) 11 check.packageObjects() 12 13 print(\u0026#34;== processDelayed ==\u0026#34;) 14 check.processDelayed(0) // incl. all functions 15 16 print(\u0026#34;== cleanup ==\u0026#34;) 17 check.cleanup() 18 19 print(\u0026#34;== initOrder ==\u0026#34;) 20 check.initOrder() 21 ... 22} initFiles() 用于检查文件开头的 package 语句所声明的名称是否符合要求，例如要跟当前 package 名一致，否则忽略这个文件（都经过词法语法分析了，白分析了，当然编译前就能检查出这些问题，一般不会进行到这里才发现）。\ncollectObjects() 在此处对 import 的 Package 进行了加载，并将其置于相应的 Scope 中。可以看到这里仍然是按照文件顺序在进行处理，通过 check.impMap 来缓存已经加载的 Package；同时用 pkgImports map[*Package]bool 来记录本 Package 已经引用的 Package，避免其重复加入 pkg.imports 数组。\n同时，还能从中看到一些特殊 import 的处理，例如 import . 和 import _ 以及别名。DotImport 会将 imported package 中的导出符号全部遍历导入到当前的 FileScope 中，而一般情况下是将 imported package 整个加入到当前的 FileScope 中，这样会有额外的层次结构。\n注意这里提到了 FileScope，我们知道在 Go 的同一个 Package 下，许多声明是不存在 FileScope 的，例如全局变量在一个文件中声明，另一个文件中可以直接使用；同名也会发生冲突，因为这些都在同一个 PackageScope 下。但是对于 import 操作来说，每个文件都有自己需要 import 的内容，因此需要一个 FileScope 来记录区分这些信息。\nScope 结构组织好后，还需要检查 FileScope 跟 PackageScope 之间的冲突问题，这主要是 DotImport 导致的。\n1// https://github.com/golang/go/blob/d8117459c513e048eb72f11988d5416110dff359/src/cmd/compile/internal/types2/resolver.go#L472 2// verify that objects in package and file scopes have different names 3for _, scope := range fileScopes { 4 for name, obj := range scope.elems { 5 if alt := pkg.scope.Lookup(name); alt != nil { 6 ... initOrder() 是对一些有依赖关系的全局声明进行排序，并未涉及 init 的处理，例如：\n1var ( 2 // a depends on b and c, c depends on f 3 a = b + c 4 b = 1 5 c = f() 6 7 // circular dependency 8 d = e 9 e = d 10) 在 Go 中，能够被用于初始化表达式的对象被称为 Dependency 对象，有 Const, Var, Func 这三类。先构建对象依赖关系的有向图（Directed Graph），再以每个节点的依赖数目为权重构建最小堆（MinHeap）并以此堆作为最小优先级队列（PriorityQueue），因此队列头部的对象总是依赖其它对象最少的，所以该队列的遍历顺序就是初始化的顺序，是很常规的处理思路。要注意常量的初始化比较简单，在构建时就已经确定，在这里仍然加入是为了检测循环依赖。\n1https://github.com/golang/go/blob/d8117459c513e048eb72f11988d5416110dff359/src/cmd/compile/internal/noder/unified.go#L209 2func writePkgStub(m posMap, noders []*noder) string { 3 // 类型检查 4 pkg, info := checkFiles(m, noders) 5 6 pw := newPkgWriter(m, pkg, info) 7 pw.collectDecls(noders) 8 ... 9 var sb strings.Builder 10 pw.DumpTo(\u0026amp;sb) 11 12 // At this point, we\u0026#39;re done with types2. Make sure the package is 13 // garbage collected. 14 freePackage(pkg) 15 16 return sb.String() 17} 最后再回到开始，可见 writePkgStub 包含了 internal/types2 的类型检查；类型检查会涉及到外部包的导出类型，也就是说会处理 import 语句；同时，类型检查的过程中也生成了一份 types2.Package 以及 types2.info，其中 types2.package 包含 Scope 层次信息以及每个 Scope 中的 Object 信息；types2.info 包含了类型检查中生成的类型信息；最后通过 pkgWriter 将这两个信息整合序列化为字符串，也就是最终得到的 data。\n实际上，这个 data 就是 Unified IR 的导出；接下来使用 pkgReader 将 data 重新构建为 IR，存储在 typecheck.Target。\n明明步骤紧接在一起，为什么要把 Unified IR 先 export 再 import 呢？ 这样做主要是为了将 Unified IR 与后续部分完全解耦，可以看到只要有 export data 就能够完成后续的编译工作；同时通过实现不同的 pkgReader，便可以从 export data 中提取出不同的信息。例如编译器需要从中读取完整的 IR； x/tools 下的工具需要对代码进行静态分析，那么就可以实现一个 pkgReader 来提取自己需要的信息，而不必再自己实现一遍词法语法分析以及类型检查。\n在 pkgReader 构建 IR 的过程中，遇到函数类型的 Object 时，做了如下处理：\n1// https://github.com/golang/go/blob/d8117459c513e048eb72f11988d5416110dff359/src/cmd/compile/internal/noder/reader.go#L750 2case pkgbits.ObjFunc: 3 if sym.Name == \u0026#34;init\u0026#34; { 4 sym = Renameinit() 5 } 6... 可见 init 函数是多么特殊，它会被重命名，这样就不会与其他 init 函数冲突了。Renameinit() 的实现如下：\n1// https://github.com/golang/go/blob/d8117459c513e048eb72f11988d5416110dff359/src/cmd/compile/internal/noder/noder.go#L419 2var renameinitgen int 3 4func Renameinit() *types.Sym { 5 s := typecheck.LookupNum(\u0026#34;init.\u0026#34;, renameinitgen) 6 renameinitgen++ 7 return s 8} 可见只是给了个编号，重命名成了一系列 init.0 init.1 init.2 等等的函数。\n至此 LoadPackage() 的工作就完成了。\npkginit.MakeInit() 接下来终于来到了 pkginit 包的内容。\n1// https://github.com/golang/go/blob/d8117459c513e048eb72f11988d5416110dff359/src/cmd/compile/internal/gc/main.go#L59 2// Main parses flags and Go source files specified in the command-line 3// arguments, type-checks the parsed Go package, compiles functions to machine 4// code, and finally writes the compiled package definition to disk. 5func Main(archInit func(*ssagen.ArchInfo)) { 6 ... 7 // Parse and typecheck input. 8 noder.LoadPackage(flag.Args()) 9 ... 10 // Create \u0026#34;init\u0026#34; function for package-scope variable initialization 11 // statements, if any. 12 // 13 // Note: This needs to happen early, before any optimizations. The 14 // Go spec defines a precise order than initialization should be 15 // carried out in, and even mundane optimizations like dead code 16 // removal can skew the results (e.g., #43444). 17 pkginit.MakeInit() 18 ... 19 // Build init task, if needed. 20 if initTask := pkginit.Task(); initTask != nil { 21 typecheck.Export(initTask) 22 } 23 ... 从注释也可以知道，在词法分析、语法分析以及类型检查和构造 IR 树的过程中，均未涉及代码优化。以下是 MakeInit() 的内容，关键部分使用中文进行了更详细的注释，可以对照相关方法的源码进行阅读。\n1// TODO(mdempsky): Move into noder, so that the types2-based frontends 2// can use Info.InitOrder instead. 3func MakeInit() { 4 // Init 相关的处理只涉及全局声明（Package Level），依赖关系作为有向边来构建有向图，然后进行拓扑排序。 5 nf := initOrder(typecheck.Target.Decls) 6 if len(nf) == 0 { 7 return 8 } 9 10 // Make a function that contains all the initialization statements. 11 base.Pos = nf[0].Pos() // prolog/epilog gets line number of first init stmt 12 // 查找 init 符号，如果 Package 的全局符号中没有则创建；不用担心 init 符号已经被用户的 init 函数使用，因为 IR 树在生成过程中遇到 init 会重命名为 init.0 init.1 这样的格式，前面提到 g.generate() 的时候也有说明。 13 initializers := typecheck.Lookup(\u0026#34;init\u0026#34;) 14 /* 用 init 符号声明一个新的函数，用于存放所有的初始化工作。具体实现是：此处在 IR 树中对应位置建立了新的 ONAME Node（ONAME 表示 var/func name），类型指定为 PFUNC，同时也将符号表中的 init 更新为 symFunc，表明这个符号是函数名；然后新建一个函数节点，将 ONAME Node 指向函数节点，最后将函数节点返回。 15 */ 16 fn := typecheck.DeclFunc(initializers, nil, nil, nil) 17 // 类型检查过程中生成了一个 InitTodoFunc，其作为全局初始化语句的临时上下文环境。现在将临时环境 InitTodoFunc 的内容转移到 fn。 18 for _, dcl := range typecheck.InitTodoFunc.Dcl { 19 dcl.Curfn = fn 20 } 21 fn.Dcl = append(fn.Dcl, typecheck.InitTodoFunc.Dcl...) 22 typecheck.InitTodoFunc.Dcl = nil 23 24 // Suppress useless \u0026#34;can inline\u0026#34; diagnostics. 25 // Init functions are only called dynamically. 26 fn.SetInlinabilityChecked(true) 27 28 // 配置函数体。 29 fn.Body = nf 30 typecheck.FinishFuncBody() 31 32 // 确定 fn 为函数节点 33 typecheck.Func(fn) 34 // 在 fn 的内部上下文环境下检查函数体 35 ir.WithFunc(fn, func() { 36 typecheck.Stmts(nf) 37 }) 38 // 把函数加入到 Package 的全局声明列表。 39 typecheck.Target.Decls = append(typecheck.Target.Decls, fn) 40 41 // Prepend to Inits, so it runs first, before any user-declared init 42 // functions. 43 typecheck.Target.Inits = append([]*ir.Func{fn}, typecheck.Target.Inits...) 44 45 if typecheck.InitTodoFunc.Dcl != nil { 46 // We only generate temps using InitTodoFunc if there 47 // are package-scope initialization statements, so 48 // something\u0026#39;s weird if we get here. 49 base.Fatalf(\u0026#34;InitTodoFunc still has declarations\u0026#34;) 50 } 51 typecheck.InitTodoFunc = nil 52} 旧版本中 MakeInit() 的工作是在 pkginit.Task() 中实现的，现在被抽取了出来，原因有以下几点。\n首先，MakeInit() 负责初始化函数的创建并插入 typecheck.Target.Inits，pkginit.Task() 得到了简化，毕竟这个初始化函数和其他用户定义的 init 实际上没有本质区别。\n其次，敏锐的同学可能发现了，类型检查的过程中，已经进行了一次 initOrder()，但只检查了循环依赖的问题；这次又 initOrder() 显得有些冗余。因此将这一部分从 Task() 中拆分出来，希望以后能够放到类型检查的过程中，避免重复的排序操作。当前抽离成了单独的函数但是还未并入类型检查，处于中间状态，可见不久后将会并入类型检查，注释中的 TODO 就是在说这个问题。\n最后，初始化函数如果在 Task() 中创建，则无法参与到类型检查结束到 Task() 开始这之间的优化过程，主要包括无效代码清理和内联优化。因此将其提前到类型检查结束后创建，这样就可以参与到优化过程中了。\npkginit.Task() 最后，终于来到了 init 处理的终点， pkginit.Task()。\n1// https://github.com/golang/go/blob/d8117459c513e048eb72f11988d5416110dff359/src/cmd/compile/internal/pkginit/init.go#L93 2// Task makes and returns an initialization record for the package. 3// See runtime/proc.go:initTask for its layout. 4// The 3 tasks for initialization are: 5// 1. Initialize all of the packages the current package depends on. 6// 2. Initialize all the variables that have initializers. 7// 3. Run any init functions. 8func Task() *ir.Name { 9 ... 10 // Find imported packages with init tasks. 11 // 这里可以看出 Package 最终的初始化任务被合并在了 .inittask 这个结构体中，因此对于引用的包才能这样进行查找，此处还检查了 .inittask 结构体是否合法。最终加入到 deps 数组。 12 for _, pkg := range typecheck.Target.Imports { 13 n := typecheck.Resolve(ir.NewIdent(base.Pos, pkg.Lookup(\u0026#34;.inittask\u0026#34;))) 14 if n.Op() == ir.ONONAME { 15 continue 16 } 17 if n.Op() != ir.ONAME || n.(*ir.Name).Class != ir.PEXTERN { 18 base.Fatalf(\u0026#34;bad inittask: %v\u0026#34;, n) 19 } 20 deps = append(deps, n.(*ir.Name).Linksym()) 21 } 22 ... 23 // 如果开启了 Address Sanitizer，那么需要在创建一个 init 函数加入 typecheck.Target.Inits，用于初始化 ASan 相关的全局变量。 24 if base.Flag.ASan { 25 ... 26 // 可见这个 init 将会在最后执行 27 typecheck.Target.Inits = append(typecheck.Target.Inits, fnInit) 28 } 29 ... 30 // Record user init functions. 31 for _, fn := range typecheck.Target.Inits { 32 // 只有处理 Package 全局变量的才叫 init，其它的都被重命名为了 init.0、init.1 等。 33 if fn.Sym().Name == \u0026#34;init\u0026#34; { 34 // Synthetic init function for initialization of package-scope 35 // variables. We can use staticinit to optimize away static 36 // assignments. 37 s := staticinit.Schedule{ 38 Plans: make(map[ir.Node]*staticinit.Plan), 39 Temps: make(map[ir.Node]*ir.Name), 40 } 41 for _, n := range fn.Body { 42 s.StaticInit(n) 43 } 44 fn.Body = s.Out 45 ir.WithFunc(fn, func() { 46 typecheck.Stmts(fn.Body) 47 }) 48 49 if len(fn.Body) == 0 { 50 fn.Body = []ir.Node{ir.NewBlockStmt(src.NoXPos, nil)} 51 } 52 } 53 54 // Skip init functions with empty bodies. 55 if len(fn.Body) == 1 { 56 if stmt := fn.Body[0]; stmt.Op() == ir.OBLOCK \u0026amp;\u0026amp; len(stmt.(*ir.BlockStmt).List) == 0 { 57 continue 58 } 59 } 60 fns = append(fns, fn.Nname.Linksym()) 61 } 最终 fns 数组保存了所有 init 函数；deps 数组保存了所有依赖的包的 .inittask 结构体。接下来合并构建自己 Package 的 .inittask。\n1// Make an .inittask structure. 2sym := typecheck.Lookup(\u0026#34;.inittask\u0026#34;) 3task := typecheck.NewName(sym) 4// 显然这个 .inittask 不是 uint8 类型的，只是为了占位，因此这里设置了一个 fake type。 5task.SetType(types.Types[types.TUINT8]) // fake type 6task.Class = ir.PEXTERN 7sym.Def = task 8lsym := task.Linksym() 9ot := 0 10// lsym.P = [0] 11ot = objw.Uintptr(lsym, ot, 0) // state: not initialized yet 12// lsym.P = [0, len(deps)] 13ot = objw.Uintptr(lsym, ot, uint64(len(deps))) 14// lsym.P = [0, len(deps), len(fns)] 15ot = objw.Uintptr(lsym, ot, uint64(len(fns))) 16// lsym.R = [newR(d)...] 17for _, d := range deps { 18 ot = objw.SymPtr(lsym, ot, d, 0) 19} 20// lsym.R = [newR(d)..., newR(f)...] 21for _, f := range fns { 22 ot = objw.SymPtr(lsym, ot, f, 0) 23} 24// An initTask has pointers, but none into the Go heap. 25// It\u0026#39;s not quite read only, the state field must be modifiable. 26// 此处说明这个 .inittask 符号是全局的，决定了最后在 object 文件中的位置区域。 27objw.Global(lsym, int32(ot), obj.NOPTR) 28return task 在最后将其设置为导出的（Export），因为其符号名并非大写字母开头，但是要被其他包使用：\n1// Build init task, if needed. 2if initTask := pkginit.Task(); initTask != nil { 3 typecheck.Export(initTask) 4} 至此，Package 单元对于 init 的处理就结束了，最后 Package 被编译为带有 .inittask 表的 object 文件，这个表中包含了所有的 init.x 函数和依赖的包的 .inittask 结构体指针，要注意这里只知道符号之间的关系，其他包里 init 函数的具体实现是不知道的，需要在链接阶段处理。\n链接时，在拥有了所有的 .inittask 包含的具体函数相关信息后，链接器会将其按照依赖关系进行排序，生成一个具体的 mainInittasks 列表供 runtime 使用。此处不再展开这一部分，有兴趣的同学可以自行阅读链接器 inittask 部分的源码：src/cmd/link/internal/ld/inittask.go，最终 SymbolName 为 go:main.inittasks。\n最终链接生成可执行文件时，inittasks 的地址会给到 src/runtime/proc.go 的 runtime_inittasks 数组变量，然后在runtime.main 函数中被使用：\n1// https://github.com/golang/go/blob/d8117459c513e048eb72f11988d5416110dff359/src/runtime/proc.go#L144 2func main() { 3 ... 4 doInit(runtime_inittasks) // Must be before defer. 5 ... 6} 最后回看一开始发现的现象：\n[现象]：a/b.go 和 a/c.go 的 init() 函数的执行顺序是按照文件名的字母顺序来的，将 a/b.go 改名后，其文件名顺序排在了 a/c.go 之后，最终 init() 执行也排在了之后。\n根源在于编译器在读取源文件时是按照文件系统文件名顺序读入，在处理时也是依文件次序处理的，也就是编译器遇到 init 和 import 的顺序都是由文件名顺序决定的。\n虽然有 initOrder() 的存在，但是它不会影响用户定义的 init() 的顺序\ninitOrder() 会处理 import 的依赖关系，因此最终各个 Package 的 init 顺序时根据依赖关系决定的。\n例如：\n1// a1.go 2import \u0026#34;b\u0026#34; 1// a2.go 2import \u0026#34;c\u0026#34; 1// b.go 2import \u0026#34;c\u0026#34; 那么不管 a1.go 和 a2.go 的文件名顺序如何，package c 都会先于 package b 初始化，因为 b 依赖 c。\n","permalink":"https://xinrea.cn/posts/go-init/","summary":"本文中引用的源码均标注了 Golang 源码仓库链接，branch 为 release-branch.go1.21（本文在编写时 Go 1.21 还未正式发布，正式版可能会","title":"从 init 函数的顺序问题到 Go 编译器"},{"content":"在学习熟悉 CubismSDK 的时候，曾给轴伊Joi制作过一个简单的 Live2D 桌面宠物；由于是在官方样例的基础上进行的修改，因此程序主题通过 glew + glfw 来进行实现。由于桌面宠物的特殊性（需要尽可能减少对桌面操作的影响），可以说是必须实现异形窗口。这个异形窗口与一般的需求还不太一样：通常异形窗口是静态的，仅以一张图片作为底图，有很多种方法可以实现，其中一种便是用蒙版（Mask）来实现，但这种方式在桌面宠物这种场景下显得有点尴尬。\n对于用 OpenGL 动态渲染的桌面宠物来说，读取当前 Buffer 生成 Mask 是效率极低的。好在 Windows 下提供了 SetLayeredWindowAttributes(hwnd,RGB(0, 0, 0), 255, LWA_COLORKEY) 这一方法，直接进行键值抠图即可。但问题是其精度极低，渲染出的模型边缘会出现很明显的底色锯齿边缘。\n在 glfw 中，通过 glfwWindowHint(GLFW_TRANSPARENT_FRAMEBUFFER, GLFW_TRUE) 可实现窗口 Buffer 新增 Alpha 通道；配合 LWA_COLORKEY 即可实现无锯齿边缘的 OpenGL 渲染的即时异形窗口。\n然而最近在使用 Qt 对其重构的过程中，又遇到了异形窗口的这一问题。Qt 提供了两种使用 OpenGL 的方式，QOpenGLWindow 与 QOpenGLWidget；这两种方式在使用上几乎没有差异，可以很方便的互相转换。但在实现异形窗口的过程中遇到了问题。\n通过实践发现，QOpenGLWidget 通过设置 Qt::WA_TranslucentBackground 可以很简单的实现透明背景；但 LWA_COLORKEY 只对 WS_EX_LAYERED 样式的窗口生效；经过测试，QOpenGLWidget 单独作为窗口时，无法设置 WS_EX_LAYERED 样式，因此无法实现异形窗口。\nQOpenGLWindow 可以直接设置 WS_EX_LAYERED 样式，但无法设置透明背景（可使用 setFormat 添加 alpha 通道属性，但配合 LWA_COLORKEY 会显示异常）；因此需要自行实现 GLFW_TRANSPARENT_FRAMEBUFFER 的功能。\n通过阅读 glfw 源码，该设置相关的代码如下所示：\n1#define DWM_BB_ENABLE 0x00000001 2#define DWM_BB_BLURREGION 0x00000002 3typedef struct 4{ 5 DWORD dwFlags; 6 BOOL fEnable; 7 HRGN hRgnBlur; 8 BOOL fTransitionOnMaximized; 9} DWM_BLURBEHIND; 10 11typedef HRESULT(WINAPI * PFN_DwmEnableBlurBehindWindow)(HWND,const DWM_BLURBEHIND*); 12 13void setTransparentBuffer(HWND hwnd) 14{ 15 auto dll = LoadLibraryA(\u0026#34;dwmapi.dll\u0026#34;); 16 auto DwmEnableBlurBehindWindow = (PFN_DwmEnableBlurBehindWindow)GetProcAddress((HMODULE) dll, \u0026#34;DwmEnableBlurBehindWindow\u0026#34;); 17 HRGN region = CreateRectRgn(0, 0, -1, -1); 18 DWM_BLURBEHIND bb = {0}; 19 bb.dwFlags = DWM_BB_ENABLE | DWM_BB_BLURREGION; 20 bb.hRgnBlur = region; 21 bb.fEnable = TRUE; 22 23 DwmEnableBlurBehindWindow(hwnd, \u0026amp;bb); 24 DeleteObject(region); 25} 最终使用 QOpenGLWindow，手动设置透明 FrameBuffer，然后设置 LWA_COLORKEY，实现了完美的 OpenGL 内容的异形窗口。\n","permalink":"https://xinrea.cn/posts/qt-opengl-semi-window/","summary":"在学习熟悉 CubismSDK 的时候，曾给轴伊Joi制作过一个简单的 Live2D 桌面宠物；由于是在官方样例的基础上进行的修改，因此程序主题通过 glew + glfw 来进行实现。由于桌面","title":"Qt OpenglWindow 异形窗口的实现"},{"content":"最近在开发的项目用到了 gRPC，并且要求使用证书进行双向认证。于是便生成了一个 CA 证书，并以此签名生成了服务端和客户端所需的各种证书，且在周五进行客户端服务端连接测试时一切正常。周末两天过去了，周一再进行测试时，连接出现了如下错误:\ntransport: authentication handshake failed: EOF\n一开始还以为是证书验证出了问题，对相关证书以及涉及到的代码进行了回退，然后进行测试，仍然出现该问题。后续经过排查，排除了证书出错的这一原因，最后莫名在重启电脑后恢复了正常。后来发现是电脑上安装的梯子导致了这一问题。该问题的产生涉及到的前置原因如下：\n由于办公网络环境较差，于是临时安装梯子，搭配手机热点进行开发工作 由于需要使用证书双向认证，在证书 SANs 中添加了域名 *.sample.com 由于证书的使用需验证域名，因此本地测试时，修改 /etc/hosts 文件将相关域名解析到了本地地址 127.0.0.1 测试用的域名匹配了代理规则 由于使用域名测试连接，匹配了代理的规则，导致本地测试的连接无法建立，出现了上述的问题。由于客户端和服务端均在本地进行测试，因此一开始并未考虑连接问题，但最终发现问题是经梯子代理导致无法建立连接。\n","permalink":"https://xinrea.cn/posts/about-grpc-connection/","summary":"最近在开发的项目用到了 gRPC，并且要求使用证书进行双向认证。于是便生成了一个 CA 证书，并以此签名生成了服务端和客户端所需的各种证书，且在周五","title":"一个 gRPC 的连接问题"},{"content":" 哔哩哔哩舰长私信助手 BiliMessenger Vue Electron\n哔哩哔哩自动化私信工具，主要用于舰长礼物链接私信分发，提供了舰长列表获取的便捷途径。\n最开始是使用 C# 来开发的 UWP 应用，并在微软应用商店上架与更新，后来使用 Vue + Electron 重构。\n桌面宠物轴伊 JPet Live2D Cubism SDK Live2D C++ OpenGL\n虚拟主播轴伊的可互动多功能 Live2D 桌面宠物。\n想着熟悉一下 Live2D SDK 开发，于是在官方样例的基础上开发了这个桌面宠物。最开始使用自己绘画\u0026amp;建模的一个轴伊Joi_Channel的团子形象 Live2D 模型，后来 轴伊Joi_Channel 提供了自身 Q 版差分立绘，逐渐改进完成了桌面宠物。\n简易提问箱 JAsk Svelte Golang\n简单的提问箱，支持话题、图片投稿等小功能，同时拥有一个简单的后台以管理投稿。\nBilibili 弹幕机 JLiverTool VanillaJS HTML Electron\nBilibili 弹幕机，除了常见的弹幕显示功能外，还支持礼物、醒目留言单独窗口显示，同时支持礼物记录本地保存管理。\n","permalink":"https://xinrea.cn/projects/","summary":"projects","title":"Projects"}]