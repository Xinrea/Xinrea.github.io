---
title: "有关数据系统的一些简要笔记"
date: 2025-02-22
draft: true
showtoc: true
tags: ["数据系统", "笔记"]
---

## 前言

> 大多数应用程序是通过一层一层叠加数据模型来构建的，如果某一层使用到了大量的数据，那么就需要一个数据系统来进行管理。

怎么理解上面这句话呢，在一整个应用系统中，一条数据可能由不同的数据模型来表示，例如：

- 在前端，数据以 JSON Object 的形式存在于内存之中，而其可能来源于 API 服务提供的 JSON 格式的一串字符；
- 这个 API 服务可能是用 Go 实现的，这条数据在构建为 JSON 字符串之前，可能在内存中以 Go Struct 的形式存在；
- API 服务可能是从 Redis 的响应中获取的数据，因此这条数据可能以 RESP（Redis 通信协议）规定的格式存在过，从 Redis 发送到 API 服务；
- Redis 能提供这条数据，说明这条数据在 Redis 的内存中以某种数据结构存在过；
- Redis 可能会将数据备份到硬盘，因此这条数据可能在硬盘上以某种格式存在过；
- 硬盘上，这条数据以某种磁场、电流的形式存在过；

那么为什么会存在这么多数据模型的转换呢？🧐

因为每一层的需求都不一样。通常来说，数据在内存中的数据模型较为直接，但是也需要根据内存的特性进行优化（对齐）；在硬盘中，可能要考虑空间利用率；在服务与服务的通讯中（协议），可能要考虑编解码性能、数据大小甚至是可阅读性；在 Redis/MySQL 等数据库中，要考虑数据的检索查找性能。

也就是说，在日常的编程过程中，无时无刻不在跟数据模型打交道，但是得益于前人的优秀设计与各种框架（各种语言内存模型与通信协议的规定），以及自身经验与最佳实践的指导，可能在无意间就选择了较优的形式来进行实现，通常情况不需要进行较为底层的数据模型的设计与选择。

但是一些应用的功能就是保存、处理和检索大量数据，例如上文提到的 Redis、MySQL 等数据库，如果想要满足需求（通用、性能与数据安全等），则需要对数据模型进行仔细地审查与设计。

针对这样的数据密集型应用系统，前人们有了许多的求索与探讨。

> 显然，你可以为每一种数据单独设计数据模型进行优化，但这是不现实的，因为数据格式多样多变，数据系统作为应用系统的底层，承载着各种各样的数据，无法对每种数据进行专门的优化，但是对某一类数据进行优化是可能的，这个类可大可小，表现了不同程度的通用性。

## 一、目标：通用

通用意味着我们需要从数据中总结出一套模式，还需要设计从这套模式中进行查询的方法。

### 1.1 通用模型设计

#### 1.1.1 层次模型

层次模型将所有数据表示为嵌套在记录中的记录（树）。显然，这种结构天然很好的支持了**一对多**的关系，但是对于**多对一**和**多对多**的关系，则没有明确的设计，因此实际使用时，要么将数据复制多份，要么留下一个引用进行手动处理（无法自动联结）；这些方式都会导致数据维护的困难。

围绕**多对多**关系的处理困境，出现了关系模型与网络模型。

#### 1.1.2 网络模型

网络模型又被称为 CODASYL 模型，是层次模型的推广。层次模型作为树结构，每个节点最多只会有一个父节点；网络模型为了更好的支持多对多关系，将其推广，每个节点允许拥有多个父节点。每次插入新节点时，相关的父节点就进行了更新，天然进行了联结，形成了新的关系结构。

为了实现这种灵活的数据关系，各个节点之间的关系变为了引用（指针）；由于过于灵活，数据访问的唯一方法是选择一条始于根目录的路径，并沿着相关链接依次访问，而这条链条也被称为访问路径。如果想要从根节点开始查询某个数据，那么需要进行大量复杂的遍历，十分低效，因此在新增相关的一组数据时，需要记录访问路径以便于后续从这些数据上检索，这使得每次查询都需要手动设定访问路径以进行优化，否则几乎不可用。

同时，在维护数据时更是十分困难，一个节点可能有多个父节点指向它，对该节点的操作会引起大量变动。

#### 1.1.3 关系模型与关系数据库

关系模型直接否定了层次模型的嵌套结构：关系（表）只是元组（行）的集合，因此关系模型能通过元组天然表示**一对一**的关系，通过扩展外键（联结）实现**一对多**、**多对一**与**多对多**。联结关系（外键）作为额外扩展功能，由关系数据库实现。在如此简洁的结构之下，查询优化器诞生了，它用于查询顺序以及索引使用的自动选择，相当于自动构建出一条优化过后的访问路径，这也是通用性的一种表现。同样的，通用也增添了复杂，由于查询操作多种多样，查询优化器变得十分庞大且复杂；但总体来说这种方式兼具了通用和性能，成为了当下的主流选择。

#### 1.1.4 文档模型与文档数据库

关系数据库中，**一对一**关系能够天然直接表示，但是常见的**一对多**关系稍微有点别扭。在表和元组的关系下，一对多需要对父进行复制或者联结（或者说在不对等的关系中，需要对少的一方进行复制或者联结）。因此层次模型因为能天然表示**一对一**和**一对多**关系，还是在一些领域有一定的优势的，特别是在本身就是嵌套结构的文档数据领域。

为了保留嵌套结构的同时实现**多对一**和**一对多**，文档数据库参考了关系数据库的实现，采用了“外键”的概念，称之为“文档引用”；这种引用的联结需要额外的操作来实现，因为其并未在结构中实际存在。

#### 1.1.5 图状数据模型

前文提到的模型在面对海量的多对多关系时仍然会力不从心，但是这种场景在现实中却是常见的，因此图状数据模型作为针对这一类数据的优化产物出现了。图由顶点和边组成，能够天然的表示多对多关系，在模式上更加的自由。具体有属性图模型和三元存储模型等类型。

#### 1.1.6 关系数据库与文档数据库的对比

关系数据库的基础结构很简单（元组），而文档数据库的基础结构为树；在文档数据库中，**一对多**关系表现为整体，而在关系数据库中则被拆分为多个元组，因此文档数据库因其局部性而具有更好的性能。在实际使用中，关系模型更多的是对现实模型的拆解，展示出其通用性；如果实际数据更符合文档模型，那么使用文档数据库会更加简洁；如果实际数据关系更加复杂（大量的多对多），那么使用图数据库会更加简洁。

1. 文档模型的灵活优势：由于文档模型中数据结构通常十分灵活，因此文档数据库通常不限制数据的具体模式，又被称之为“无模式”，但显然模式是存在的，只是交给了应用层处理，被称之为**读时模式**；与之对应的关系数据库则限制写入时数据的模式，要求其符合规则，又被称之为**写时模式**。
2. 数据局部性的优劣：文档模型与层次模型类似，基础结构为树，在读取时则以树为单位，因此相关联的数据会被同时读取，如果要访问文档内大部分内容的话，则具有较强的局部性优势；但如果只是读取或者修改文档中的一小部分的话，就有点得不偿失，表现为劣势。如果修改后文档大小发生变化（主要是文档增大后），那么文档树甚至不能覆盖保存回原位置，而是需要重新分配。

#### 1.1.7 关系数据库与文档数据库的融合

最简单的例子便是关系数据库的元组中支持 XML、JSON 等文档数据结构。

### 1.2 通用查询设计

数据库数据模型的设计十分重要，但是考虑到数据库的主要功能之一：查询，设计出一种通用的查询方法也是至关重要的。与一般的程序调用 lib 不同，数据库存储着大量不同的模式，为了在这些模式上实现通用的查询等操作，数据库的接口必须十分灵活，这促使了数据查询语言的出现。

1. 命令式：网络模型（CODASYL）在前文中提到，每次查询需要设定访问路径，这个设定便是通过命令式查询语言实现的，这要求用户需要自行组织具体的查询逻辑；
2. 声明式：关系数据库所使用的声明式查询语言（SQL 或关系代数）只需制定所需的数据模式、条件以及转换规则，查询优化器会组织具体的查询逻辑步骤，这意味着只要不断优化查询优化器，无需对查询语句修改即可实现性能提升。而且随着多核处理器的出现以及大尺度上集群的出现，声明式更适合查询优化器生成并行查询的逻辑操作，大大提高查询效率，可以说是适应了时代的潮流。
3. MapReduce：是一种混合命令与声明的查询方式，通过将命令式的纯函数代码片段复用，适应了集群分布执行的环境，可以作为 SQL 等声明式查询语言具体执行时的基础操作。

图状数据模型中，声明式和命令式查询语言都有。

### 1.3 模型的实现

数据库，即采用了这些数据模型的数据系统，主要功能就是存储和查询。由于数据库作为专门存储和检索数据的系统，常常存储着远超系统内存大小的数据，为了同时管理内存和硬盘中的数据，引入了存储引擎的概念；就算以内存数据库著称的 Redis 等系统，为了数据安全通常也会启用持久化备份，同样需要管理内存和硬盘中的数据。

数据库的核心，或者说存储引擎的核心是数据结构，我们以最简单的 kv 数据库为例，一步步探讨存储引擎的设计。

假设 kv 数据按照更新顺序，依次写入文件尾部，那么在查找某个 key 时，我们从文件尾部向前扫描，找到的第一个值即为最新的值，复杂度显然为 $$O(n)$$

我们把这个硬盘文件称之为**段文件**，显然对于拥有大量数据的数据库来说，这是不可接受的；因此还必须引入索引的概念，即帮助定位数据的元数据。显然写入文件尾部这一操作已经是数据写入的最简操作了，任何额外的元数据构建或者说索引的引入，都会降低写入性能。在这一简易场景下，最简单的索引便是 HashMap，也称之为哈希索引。在这里我们拥有了追加写段文件与哈希索引，分别存在于硬盘和内存中，结合起来完成数据的管理。

#### 1.3.1 追加写段文件 + 哈希索引

追加写段文件在添加数据时具有极好的性能，因为其基础操作是最简单的往文件尾添加数据；虽然会有许多旧值存在，但是通过扫描段文件能很轻易地实现段文件的整理和压缩，保留每个 key 最新的值，只需在后台定期压缩即可。考虑到单文件过大带来的问题，追加写段文件能很轻易地在文件大小达到阈值后进行分段，只需要写入新文件即可；对于这些段文件的压缩和合并可以定时在后台完成。

在内存的 HashMap 中记录硬盘上**每个** key 的偏移值，这样查询能在 O(1) 完成；这个 HashMap 能够通过扫描段文件构建，或者是构建完成后保存在硬盘中，重启后读取构建。如果进行了分段，那么每一段都有其对应的 HashMap，在查找时只需要根据段的新旧顺序，从新往旧搜索即可。

两者的配合可以实现数据量较小情况下的高性能数据库。但由于哈希索引的设计问题，导致

1. 系统内存需要能够容纳所有的 key;
2. 由于段文件无序，区间查询时只能通过哈希索引在段文件中跳来跳去读取，拼凑出区间结果，效率很低。

#### 1.3.2 有序段文件 SSTABLE + 哈希索引

为了解决前文提到的问题，很容易想到将段文件设计为有序的，相对应的有两大好处：

1. 系统内存中只需记录部分 key 的位置，当查询某个 key 时，只要能找到其可能所在的区间就可以了；
2. 段内数据有序，因此在段内可以通过二分查找 key 的具体位置。

显然，不能只规定说段文件有序就行了，需要思考 🤔 如何维护其有序的状态：

1. 显然不能直接往段文件尾部追加写了，这样无法维持其有序的状态，所以必须在内存中缓存一部分的数据，我们称之为**内存表**，当其达到一定的量后再排序写入段文件（或者从一开始就使用有序数据结构来管理，例如红黑树，避免写前排序），这样产生的段文件就都是有序的了；
2. 如果系统崩溃，那么内存中缓存的部分数据会丢失，因此还是要将其持久化到硬盘，以便于恢复；显然，可以使用前文中追加写段文件的形式来持久化这部分数据，由于我们已经规定段文件有序，那么这个“追加写段文件”我们便另外称之为“追加写日志”，不参与查询和合并操作，只用于故障恢复；
3. 对于段文件的压缩，有序后反而更简单了，不必将两个段文件完全读入内存便可以完成合并压缩工作，因此这部分不受影响；
4. 还有一点细节，当内存数据写入有序段文件后，这部分的追加写日志便失去了作用，可以丢弃了。

**要注意的是，上述过程中所有写入硬盘的操作都是顺序写，因此写性能极高。**

> 这部分所提到的段文件的维护方式，正是 LevelDB 和 RocksDB 所使用的；而前文提到的直接追加写的方式，则是 Bitcask 所使用的。

基于合并和压缩排序文件原理的存储引擎通常被称为 LSM 存储引擎；其中 LSM 表示 Log-Structured Merge，原因是这些有序段文件实际上是追加写的日志文件演变而来，且基于这些文件的压缩合并。这个结构也被称为 LSM-Tree（日志结构的合并树），原因是实践过程中，有序段文件的合并并不是随意进行的，我们将最基础零碎的段文件不断合并后，会形成一系列经历过一次合并的段文件，而这些段文件还能进行合并，依此类推，是存在层级结构的，这样便形成了树；我们可以针对不同层级采取不同的压缩策略。

#### 1.3.3 B-Tree

前文提到的 LSM 存储引擎虽然简单好用，但是仍有其缺陷：

1. 其后台进行的合并压缩操作会占据一定的硬盘读写带宽，如果数据量巨大，合并压缩操作完全占据了磁盘的读写带宽，那么数据库便无法对外提供服务；
2. 就算没有全部占据，合并压缩操作也会对服务请求的处理产生影响，造成随机的响应延迟，有点类似于带有 GC 机制的语言的缺点；
3. 其次，不同的段文件中可能包含 key 新旧时期不同的值，为事务语义的实现增添了不少风险；
4. 读取性能较弱，虽然用布隆过滤器可以避免许多不必要的查找操作，但是搜索范围可能涉及多个段文件的读取；
5. 二级索引实现困难。

> 关于索引与存储引擎，显然存储引擎为了实现高效的查找功能，在存储设计时一定会有对应的索引设计，就如上文中的哈希索引一样，在 kv 数据库中表现为 key 的索引；在关系数据库中表现为主键的索引（必定有一个这样的索引）。在这个主索引之外，通常还需要创建二级索引，以加速非主键上的查询操作。

有没有响应时间稳定，读取性能更好，二级索引简单的存储引擎选择呢 🤔？那就是老牌的 B-Tree 了。

B-Tree 把数据库分解成固定大小的块或页，页是内部读写的最小单元，与磁盘的块排列设计相匹配；每个页面都可以用其在磁盘上的位置进行标识，相当于磁盘上的指针。其中一个页作为 B-Tree 的根，所有的查询操作都从这里开始。

页中包含键和其他页的引用，每个引用代表着一个连续范围内的键，相邻引用之间的键可以指示这些范围的边界，这些数据都是有序存放的，便于二分查找。B-Tree 中一页所包含的引用数称为分支因子，实际中这个因子会收到页大小等因素的影响，会达到几百。

在 B-Tree 中更新某个 key 时，首先要找到其值所在的叶子页，然后将其修改后覆盖整个叶子页；如果添加某个 key 时，其值应在的叶子页已满，那么就需要进行分裂操作。分裂操作意味着原来指向叶子页的引用也将变成两个，因此会涉及到父页、原叶子页与两个新叶子页的处理；如果删除某个 key 后仍然要使 B-Tree 保持平衡，那么需要更多额外的操作。

平衡状态下，具有 n 个键的 B-Tree 总是具有 O(logn)的深度，具有优秀的查询性能。
